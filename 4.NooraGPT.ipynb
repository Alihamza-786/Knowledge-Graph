{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430d9fd5-fa59-4fc0-8730-815ba30be2d3",
   "metadata": {},
   "source": [
    "# Project Summary\n",
    "NooraGPT is an AI-powered assistant designed to handle internal queries related to the Home Salon by Nooora business operations. It leverages a Neo4j graph database and a local open-source LLM (Ollama + Qwen 2.5) to generate natural responses for business-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6d365c-0401-45c7-b11e-f565a69ae8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import uuid\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from py2neo import Graph\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ad3864-c9fe-4a25-b458-ed2cf7849c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5\", temperature=0.1, streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9181ade-6149-4f0f-944f-78af9be014dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"\"\"\n",
    "- Employee /\n",
    "- Department /\n",
    "- Skill /\n",
    "- Customer /\n",
    "- Vehicle /\n",
    "- Task /\n",
    "\"\"\"\n",
    "\n",
    "relationships = \"\"\"\n",
    "- (Employee)-[:WORKS_IN]->(Department) /\n",
    "- (Employee)-[:HAS_SKILL]->(Skill) /\n",
    "- (Task)-[:HAS_CUSTOMER]->(Customer) /\n",
    "- (Task)-[:HAS_DRIVER]->(Employee) /\n",
    "- (Task)-[:USES_VEHICLE]->(Vehicle) /\n",
    "- (Task)-[:SELECTED_TECHNICIAN]->(Employee) /\n",
    "\"\"\"\n",
    "\n",
    "departments = \"\"\"\n",
    "- Administration /\n",
    "- Unknown Department /\n",
    "- Technician Team /\n",
    "- Drivers /\n",
    "- Customer Support Team /\n",
    "- Human Resource Department /\n",
    "\"\"\"\n",
    "\n",
    "employee_properties = \"\"\"\n",
    "- contact: str /\n",
    "- email: str /\n",
    "- gender: str /\n",
    "- id: int /\n",
    "- job_title: str /\n",
    "- name: str /\n",
    "- private_address: str /\n",
    "- skill_tags: list /\n",
    "- working_shift: str /\n",
    "\"\"\"\n",
    "\n",
    "customer_properties = \"\"\"\n",
    "- address: str /\n",
    "- contact: str /\n",
    "- email: str /\n",
    "- gender: str /\n",
    "- id: int /\n",
    "- map_url: str /\n",
    "- name: str /\n",
    "\"\"\"\n",
    "\n",
    "vehicle_properties = \"\"\"\n",
    "- id: int /\n",
    "- license_plate: str /\n",
    "- name: str /\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551cd7ba-fcbd-4f3e-a392-6d976e30bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are a helpful Cypher query generator. Your task is to generate only the Cypher query in response to user questions about a Neo4j graph.\n",
    "Do not include explanations or comments in your response.\n",
    "\n",
    "The schema is as follows:\n",
    "--------------------------\n",
    "The Neo4j graph has the following node labels: {labels}\n",
    "The following relationships: {relationships}\n",
    "The 'Department' nodes are as follows: {departments}\n",
    "The 'Employee' properties are: {employee_properties}\n",
    "The 'Vehicle' properties are: {vehicle_properties}\n",
    "----------------------------\n",
    "\n",
    "Here are some examples:\n",
    "Example 1: For the question \"Give email address of customer whose id is 96982\"\n",
    "MATCH (c:Customer {{{{id: 96982}}}})\n",
    "RETURN c.email\n",
    "\n",
    "Example 2: For the question \"Who is the HR?\"\n",
    "MATCH (e:Employee)-[:WORKS_IN]->(d:Department {{{{name: 'Human Resource Department'}}}})\n",
    "RETURN e.name\n",
    "\n",
    "Example 3: For the question \"Give contact number of employee whose id is 462\"\n",
    "MATCH (e:Employee {{{{id: 462}}}})\n",
    "RETURN e.contact\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa19dc8-3ef4-45f4-824a-cbcdd3add579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prompt for generating Cypher\n",
    "generate_cypher_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0a9810-4530-4ac8-b6f1-6071b86dd62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Function to run Cypher on Neo4j\n",
    "def run_cypher(cypher: str) -> dict:\n",
    "    result = graph.run(cypher).data()\n",
    "    return {\"results\": result}\n",
    "\n",
    "# 4. Prompt for final answer generation\n",
    "def generate_natural_language_prompt(data: dict) -> str:\n",
    "    return f\"\"\"\n",
    "You are NooraGPT, a helpful assistant for 'Home Salon by Nooora', which provides home salon services in Dubai.  \n",
    "You are given a user question and the answer fetched from a graph database.  \n",
    "Your task is to write a short, natural response for the user.\n",
    "\n",
    "If the userâ€™s question is general or unrelated to Noora's internal operations, and the Database Result is empty, \n",
    "politely inform them that you can only answer questions about Nooraâ€™s internal information.\n",
    "\n",
    "The database contains the following labels: {labels}\n",
    "\n",
    "Question: ```{data['user']}```\n",
    "Database Result: ```{data['results']}```\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0b727f-c75b-4fdc-be51-161f16e15fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¬ Final Answer:\n",
      " Hello! The HR representative at Noora is Pranali Ramkrishna Kadam. If you have any questions or need assistance related to our services, feel free to reach out! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# 5. Build the pipeline\n",
    "pipeline = (\n",
    "    generate_cypher_prompt\n",
    "    | llm\n",
    "    | (lambda msg: {\"user\": user_question, \"cypher\": msg.content})\n",
    "    | (lambda d: {**d, **run_cypher(d[\"cypher\"])})\n",
    "    | (lambda d: generate_natural_language_prompt(d))\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 6. Run it\n",
    "user_question = \"who is HR\"\n",
    "final_response = pipeline.invoke({\"query\": user_question})\n",
    "print(\"\\nðŸ’¬ Final Answer:\\n\", final_response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd8aa2e-bf91-4db7-875a-67825efd303e",
   "metadata": {},
   "source": [
    "# User Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f937f596-cc5a-4db4-944d-be338f621998",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    generate_cypher_prompt\n",
    "    | llm\n",
    "    | (lambda msg: {\n",
    "        \"user\": msg.additional_kwargs.get(\"query\"),  # extract saved query\n",
    "        \"cypher\": msg.content\n",
    "      })\n",
    "    | (lambda d: {**d, **run_cypher(d[\"cypher\"])})\n",
    "    | (lambda d: generate_natural_language_prompt(d))\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f35da3-6652-4471-9ae6-1d7dab3b9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_loop():\n",
    "    session_id = str(uuid.uuid4())\n",
    "    print(\"NooraGPT is ready to assist you with internal operations.\\nType 'q' or 'quit' to exit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"ðŸ§‘ You: \")\n",
    "        if user_input.lower() in [\"q\", \"quit\"]:\n",
    "            print(\"ðŸ‘‹ NooraGPT: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        print(\"ðŸ¤– NooraGPT: \", end=\"\", flush=True)\n",
    "\n",
    "        async for chunk in pipeline.astream(\n",
    "            {\"query\": user_input},  # query used for prompt\n",
    "            config={\"configurable\": {\"session_id\": session_id}}\n",
    "        ):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "519e8acf-8fe2-4f01-b620-ce781d6a5aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NooraGPT is ready to assist you with internal operations.\n",
      "Type 'q' or 'quit' to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ðŸ§‘ You:  who is hr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– NooraGPT: Hello! The information I found in our records shows that the employee name is Pranali Ramkrishna Kadam. If you have any specific questions about her or need more details, feel free to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ðŸ§‘ You:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‹ NooraGPT: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "await chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcdc6f-1760-41d4-99ef-b885144c03d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
